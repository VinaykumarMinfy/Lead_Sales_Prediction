## ğŸš€ Lead Conversion Prediction System
This project builds a scalable, explainable ML system that predicts whether a lead will convert, enabling sales/marketing teams to focus on high-potential leads.

ğŸ“Œ Project Goal
To develop a robust ML pipeline to:

ğŸ¯ Predict lead conversion (binary classification: 0 = Not Converted, 1 = Converted)

ğŸ“ˆ Maximize conversion rate and sales ROI

ğŸ” Provide explainable predictions via SHAP

ğŸ“Š Monitor model/data drift with Evidently

ğŸ“¦ Deploy the model with Flask + PostgreSQL

## ğŸ—ƒï¸ Dataset Summary
Feature	Description
Converted	Target variable (0 or 1)
Do Not Email, Do Not Call	Binary features (Yes/No)
TotalVisits, Time on Website	Numerical engagement metrics
Source, Specialization	Categorical attributes
Asymmetrique_* features	Ordinal behavioral scoring

## ğŸ—ï¸ Architecture Overview
java
Copy
Edit
CSV/DB â†’ Preprocessing â†’ Model Training â†’ MLflow Logging/Registry
         â†“                                     â†“
    SMOTE Balancing                     Model Deployment (Flask)
         â†“                                     â†“
     Evaluation (ROC, F1)       Predictions â†’ PostgreSQL â†’ Results
         â†“                                     â†“
    SHAP Explainability             Evidently Drift Monitoring
## ğŸ§° Libraries Used
txt
Copy
Edit
Python 3.10.11
pandas, numpy, matplotlib, seaborn
scikit-learn, imblearn, xgboost
mlflow, shap, evidently
sqlalchemy, psycopg2-binary, flask
joblib, warnings, re, os
âš™ï¸ Setup Instructions
ğŸ”§ 1. Create and Activate Environment
bash
Copy
Edit
conda create -n leadenv python=3.10.11
conda activate leadenv
## 2. Install Required Packages
bash
Copy
Edit
pip install -r requirements.txt
## 3. Setup .env (for PostgreSQL)
ini
Copy
Edit
DB_USER=postgres
DB_PASSWORD=vinay
DB_HOST=localhost
DB_PORT=5432
DB_NAME=mydb1
##  ğŸ§ª Model Training Pipeline
## ğŸ“‚ Data Preparation
python
Copy
Edit
df = pd.read_csv("Lead Scoring.csv")
df.replace(["Select", ""], np.nan, inplace=True)
ğŸ› ï¸ Preprocessing
Ordinal encoding: asymmetrique_activity_index, asymmetrique_profile_index

Binary encoding for Yes/No columns

OneHot encoding for categoricals

Scaling for numerical values

Pipeline saved as preprocess.pkl

ğŸ§ª Class Balancing with SMOTE
python
Copy
Edit
smote = SMOTE(random_state=42)
X_balanced, y_balanced = smote.fit_resample(X_preprocessed, y)
##  MLflow Integration
Automatically tracks metrics, parameters, SHAP plots

Registers best model (based on ROC-AUC)

Automatically transitions to Production stage

Sample log:

python
Copy
Edit
mlflow.log_metric("roc_auc", 0.91)
mlflow.sklearn.log_model(best_model, "model")
ğŸ¤– Model Deployment (Flask)
## Files
app.py: Flask server with /predict

upload.html: Upload CSV

results.html: Display predictions in tabular format

Saves results to PostgreSQL (lead_scoring table)

## Auto-load Model from MLflow
python
Copy
Edit
from mlflow.tracking import MlflowClient

def get_latest_production_model_name(stage="Production"):
    ...
    return model_name

model_name = get_latest_production_model_name()
model_uri = f"models:/{model_name}/Production"
pipeline = mlflow.pyfunc.load_model(model_uri)
## Drift Monitoring (Evidently)
Prepares train, val, and test sets

Applies preprocessing

Uses Evidently to generate and log drift reports to MLflow

python
Copy
Edit
from evidently.report import Report
report = Report(metrics=[DataDriftPreset()])
report.run(reference_data=X_train, current_data=X_test)
report.save_html("drift_report.html")
mlflow.log_artifact("drift_report.html")
ğŸ§ª Sample Prediction Flow
bash
Copy
Edit
## Run Flask server
python app.py

## Go to: http://localhost:5001
 Upload CSV file with required columns
 Get predictions + PostgreSQL save
 ğŸ“„ File Checklist
File	Purpose
app.py	Flask prediction server
upload.html	CSV upload form
results.html	Prediction table output
requirements.txt	Package list
.env	Environment variables
preprocess.pkl	Saved preprocessing pipeline

## âœ… Best Practices Followed
ğŸ§¼ Clean column names and handle missing values

ğŸ’¡ Explainable ML with SHAP

âš–ï¸ SMOTE to handle class imbalance

ğŸ“¦ MLflow for end-to-end experiment tracking

ğŸ§  Drift tracking with Evidently

ğŸš€ Fully automated production deployment via Flask
