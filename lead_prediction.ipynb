{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Importing Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 732
        },
        "id": "YvqhnLWZqPM1",
        "outputId": "e9269b0e-a019-4bd2-e3a0-8618ccad53cf"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import joblib\n",
        "import os\n",
        "import time\n",
        "from sqlalchemy import create_engine\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder,OrdinalEncoder\n",
        "from sklearn.impute import SimpleImputer\n",
        "from feature_engine.outliers import Winsorizer\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
        "from mlflow.tracking import MlflowClient\n",
        "from evidently.report import Report\n",
        "from evidently.metric_preset import DataDriftPreset\n",
        "import re\n",
        "import shap\n",
        "import mlflow\n",
        "import mlflow.sklearn\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Load data from Postgres"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 236,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CSV file loaded successfully.\n",
            "Data uploaded to PostgreSQL table 'leadprediction'.\n",
            "Data read back from PostgreSQL:\n",
            "                            Prospect ID  Lead Number              Lead Origin  \\\n",
            "0  7927b2df-8bba-4d29-b9a2-b6e0beafe620       660737                      API   \n",
            "1  2a272436-5132-4136-86fa-dcc88c88f482       660728                      API   \n",
            "2  8cc8c611-a219-4f35-ad23-fdfd2656bd8a       660727  Landing Page Submission   \n",
            "3  0cc2df48-7cf4-4e39-9de9-19797f9b38cc       660719  Landing Page Submission   \n",
            "4  3256f628-e534-4826-9d63-4a8b88782852       660681  Landing Page Submission   \n",
            "\n",
            "      Lead Source Do Not Email Do Not Call  Converted  TotalVisits  \\\n",
            "0      Olark Chat           No          No          0          0.0   \n",
            "1  Organic Search           No          No          0          5.0   \n",
            "2  Direct Traffic           No          No          1          2.0   \n",
            "3  Direct Traffic           No          No          0          1.0   \n",
            "4          Google           No          No          1          2.0   \n",
            "\n",
            "   Total Time Spent on Website  Page Views Per Visit  ...  \\\n",
            "0                            0                   0.0  ...   \n",
            "1                          674                   2.5  ...   \n",
            "2                         1532                   2.0  ...   \n",
            "3                          305                   1.0  ...   \n",
            "4                         1428                   1.0  ...   \n",
            "\n",
            "  Get updates on DM Content    Lead Profile    City  \\\n",
            "0                        No          Select  Select   \n",
            "1                        No          Select  Select   \n",
            "2                        No  Potential Lead  Mumbai   \n",
            "3                        No          Select  Mumbai   \n",
            "4                        No          Select  Mumbai   \n",
            "\n",
            "  Asymmetrique Activity Index Asymmetrique Profile Index  \\\n",
            "0                   02.Medium                  02.Medium   \n",
            "1                   02.Medium                  02.Medium   \n",
            "2                   02.Medium                    01.High   \n",
            "3                   02.Medium                    01.High   \n",
            "4                   02.Medium                    01.High   \n",
            "\n",
            "  Asymmetrique Activity Score Asymmetrique Profile Score  \\\n",
            "0                        15.0                       15.0   \n",
            "1                        15.0                       15.0   \n",
            "2                        14.0                       20.0   \n",
            "3                        13.0                       17.0   \n",
            "4                        15.0                       18.0   \n",
            "\n",
            "  I agree to pay the amount through cheque  \\\n",
            "0                                       No   \n",
            "1                                       No   \n",
            "2                                       No   \n",
            "3                                       No   \n",
            "4                                       No   \n",
            "\n",
            "  A free copy of Mastering The Interview Last Notable Activity  \n",
            "0                                     No              Modified  \n",
            "1                                     No          Email Opened  \n",
            "2                                    Yes          Email Opened  \n",
            "3                                     No              Modified  \n",
            "4                                     No              Modified  \n",
            "\n",
            "[5 rows x 37 columns]\n"
          ]
        }
      ],
      "source": [
        "# This is for Data ingestion from PostgreSQL database.\n",
        "def data_ingestion():\n",
        "    try:\n",
        "        # Step 1: Read CSV file\n",
        "        df = pd.read_csv(\"Lead Scoring.csv\")\n",
        "        print(\"CSV file loaded successfully.\")\n",
        "\n",
        "        # Step 2: Create SQLAlchemy engine\n",
        "        engine = create_engine(\"postgresql+psycopg2://postgres:vinay@localhost:5432/mydb1\")\n",
        "\n",
        "        # Step 3: Upload data to PostgreSQL (replace existing table)\n",
        "        df.to_sql(\"leadprediction\", con=engine, if_exists='replace', index=False)\n",
        "        print(\"Data uploaded to PostgreSQL table 'leadprediction'.\")\n",
        "\n",
        "        # Step 4: Read back from PostgreSQL\n",
        "        query = \"SELECT * FROM leadprediction\"\n",
        "        df_from_db = pd.read_sql_query(query, con=engine)\n",
        "        print(\"Data read back from PostgreSQL:\")\n",
        "\n",
        "        # Step 5: Preview the data\n",
        "        print(df_from_db.head())\n",
        "        return df_from_db\n",
        "    except Exception as e:\n",
        "        print(\"Error during data ingestion:\", e)\n",
        "        return None\n",
        "# Call the function\n",
        "df = data_ingestion()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Here i used glook AutoEDA(Univarient,Bivarient) for Analysis and that files are present in AutoEDA folder "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Univarient analysis\n",
        "1. Prospect ID-\n",
        "Unique identifier, not useful for modeling.\n",
        "2. Lead Number-\n",
        "Serial/ID, no predictive value.\n",
        "\n",
        "3. Lead Origin-\n",
        "5 categories; mostly clean.\n",
        "\n",
        "4. Lead Source-\n",
        "21 categories; includes similar/duplicate values and minor typos (e.g., \"Google\", \"google\").\n",
        "\n",
        "5. Do Not Email-\n",
        "Binary (Yes/No); suitable for encoding.\n",
        "\n",
        "6. Do Not Call-\n",
        "Binary (Yes/No); suitable for encoding.\n",
        "\n",
        "7. Converted-\n",
        "Target variable; imbalanced (≈39% positive).\n",
        "\n",
        "8. TotalVisits-\n",
        "Numeric; long tail, some outliers.\n",
        "\n",
        "9. Total Time Spent on Website-\n",
        "Numeric; wide spread, some high values.\n",
        "\n",
        "10. Page Views Per Visit-\n",
        "Numeric; mostly low values, some outliers.\n",
        "\n",
        "11. Last Activity-\n",
        "17 categories; variety of user/customer actions.\n",
        "\n",
        "12. Country-\n",
        "38 categories; \"unknown\" and \"India\" dominate.\n",
        "\n",
        "13. Specialization-\n",
        "19 categories; contains “Select” and missing (nan) values.\n",
        "\n",
        "14. How did you hear about X Education-\n",
        "10 categories; many \"Select\" and missing.\n",
        "\n",
        "15. What is your current occupation-\n",
        "6 categories; \"Unemployed\" & \"Student\" common, some missing.\n",
        "\n",
        "16. What matters most to you in choosing a course-\n",
        "3 categories; some missing.\n",
        "\n",
        "17. Search-\n",
        "Binary; yes/no, can encode.\n",
        "\n",
        "18. Magazine-\n",
        "Only \"No;\" zero variance, drop column.\n",
        "\n",
        "19. Newspaper Article-\n",
        "Binary; yes/no.\n",
        "\n",
        "20. X Education Forums-\n",
        "Binary; yes/no.\n",
        "\n",
        "21. Newspaper-\n",
        "Binary; yes/no.\n",
        "\n",
        "22. Digital Advertisement-\n",
        "Binary; yes/no.\n",
        "\n",
        "23. Through Recommendations-\n",
        "Binary; yes/no.\n",
        "\n",
        "24. Receive More Updates About Our Courses-\n",
        "Only \"No;\" zero variance, drop column.\n",
        "\n",
        "25. Tags\n",
        "26 categories; needs grouping, long tail distribution.-\n",
        "\n",
        "26. Lead Quality\n",
        "5 categories; contains missing (nan) values.-\n",
        "\n",
        "27. Update me on Supply Chain Content-\n",
        "Only \"No;\" zero variance, drop column.\n",
        "\n",
        "28. Get updates on DM Content\n",
        "Only \"No;\" zero variance, drop column.\n",
        "\n",
        "29. Lead Profile-\n",
        "6 categories; has \"Select\" and missing values.\n",
        "\n",
        "30. City-\n",
        "7 categories; contains \"Select\" and missing values.\n",
        "\n",
        "31. Asymmetrique Activity Index-\n",
        "3 ordinal categories (Low, Medium, High), some missing.\n",
        "\n",
        "32. Asymmetrique Profile Index-\n",
        "3 ordinal categories (Low, Medium, High), some missing.\n",
        "\n",
        "33. Asymmetrique Activity Score-\n",
        "Numeric score, moderate range, no strong outliers.\n",
        "\n",
        "34. Asymmetrique Profile Score-\n",
        "Numeric score, somewhat higher range, no strong outliers.\n",
        "\n",
        "35. I agree to pay the amount through cheque-\n",
        "Only \"No;\" zero variance, drop column.\n",
        "\n",
        "36. A free copy of Mastering The Interview-\n",
        "Binary; yes/no.\n",
        "\n",
        "37. Last Notable Activity-\n",
        "16 categories; user’s last major action/event."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Bivarient Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Correlation between Features and Converted:\n",
        "\n",
        "All numeric features (such as Total Visits, Total Time Spent on Website, Page Views Per Visit, Asymmetrique Activity Score, Asymmetrique Profile Score) show very weak correlation with the target variable (Converted)—coefficients are close to zero, with the largest observed at only 0.36 for Total Time Spent on Website.\n",
        "\n",
        "Feature Interrelationships:\n",
        "\n",
        "Highest correlations are between Total Visits and Page Views Per Visit (0.51) and between Total Time Spent on Website and Page Views Per Visit (0.32), suggesting some features may contain overlapping information or redundancy.\n",
        "\n",
        "Lead Number:\n",
        "\n",
        "As expected, shows no meaningful correlation with any variable; should continue to be excluded from modeling.\n",
        "\n",
        "Overall:\n",
        "\n",
        "No single feature is a strong bivariate predictor of conversion.\n",
        "\n",
        "Models will likely need to leverage combinations of features or more advanced methods (like tree-based interactions) to distinguish converted leads.\n",
        "\n",
        "If you need comments on specific variable pairs or details from scatterplots or other plot outputs, please specify!\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Prospect ID</th>\n",
              "      <th>Lead Number</th>\n",
              "      <th>Lead Origin</th>\n",
              "      <th>Lead Source</th>\n",
              "      <th>Do Not Email</th>\n",
              "      <th>Do Not Call</th>\n",
              "      <th>Converted</th>\n",
              "      <th>TotalVisits</th>\n",
              "      <th>Total Time Spent on Website</th>\n",
              "      <th>Page Views Per Visit</th>\n",
              "      <th>...</th>\n",
              "      <th>Get updates on DM Content</th>\n",
              "      <th>Lead Profile</th>\n",
              "      <th>City</th>\n",
              "      <th>Asymmetrique Activity Index</th>\n",
              "      <th>Asymmetrique Profile Index</th>\n",
              "      <th>Asymmetrique Activity Score</th>\n",
              "      <th>Asymmetrique Profile Score</th>\n",
              "      <th>I agree to pay the amount through cheque</th>\n",
              "      <th>A free copy of Mastering The Interview</th>\n",
              "      <th>Last Notable Activity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>7927b2df-8bba-4d29-b9a2-b6e0beafe620</td>\n",
              "      <td>660737</td>\n",
              "      <td>API</td>\n",
              "      <td>Olark Chat</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>No</td>\n",
              "      <td>Select</td>\n",
              "      <td>Select</td>\n",
              "      <td>02.Medium</td>\n",
              "      <td>02.Medium</td>\n",
              "      <td>15.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>Modified</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2a272436-5132-4136-86fa-dcc88c88f482</td>\n",
              "      <td>660728</td>\n",
              "      <td>API</td>\n",
              "      <td>Organic Search</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>674</td>\n",
              "      <td>2.5</td>\n",
              "      <td>...</td>\n",
              "      <td>No</td>\n",
              "      <td>Select</td>\n",
              "      <td>Select</td>\n",
              "      <td>02.Medium</td>\n",
              "      <td>02.Medium</td>\n",
              "      <td>15.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>Email Opened</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8cc8c611-a219-4f35-ad23-fdfd2656bd8a</td>\n",
              "      <td>660727</td>\n",
              "      <td>Landing Page Submission</td>\n",
              "      <td>Direct Traffic</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>1</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1532</td>\n",
              "      <td>2.0</td>\n",
              "      <td>...</td>\n",
              "      <td>No</td>\n",
              "      <td>Potential Lead</td>\n",
              "      <td>Mumbai</td>\n",
              "      <td>02.Medium</td>\n",
              "      <td>01.High</td>\n",
              "      <td>14.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Email Opened</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0cc2df48-7cf4-4e39-9de9-19797f9b38cc</td>\n",
              "      <td>660719</td>\n",
              "      <td>Landing Page Submission</td>\n",
              "      <td>Direct Traffic</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>305</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>No</td>\n",
              "      <td>Select</td>\n",
              "      <td>Mumbai</td>\n",
              "      <td>02.Medium</td>\n",
              "      <td>01.High</td>\n",
              "      <td>13.0</td>\n",
              "      <td>17.0</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>Modified</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3256f628-e534-4826-9d63-4a8b88782852</td>\n",
              "      <td>660681</td>\n",
              "      <td>Landing Page Submission</td>\n",
              "      <td>Google</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>1</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1428</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>No</td>\n",
              "      <td>Select</td>\n",
              "      <td>Mumbai</td>\n",
              "      <td>02.Medium</td>\n",
              "      <td>01.High</td>\n",
              "      <td>15.0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>Modified</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 37 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                            Prospect ID  Lead Number              Lead Origin  \\\n",
              "0  7927b2df-8bba-4d29-b9a2-b6e0beafe620       660737                      API   \n",
              "1  2a272436-5132-4136-86fa-dcc88c88f482       660728                      API   \n",
              "2  8cc8c611-a219-4f35-ad23-fdfd2656bd8a       660727  Landing Page Submission   \n",
              "3  0cc2df48-7cf4-4e39-9de9-19797f9b38cc       660719  Landing Page Submission   \n",
              "4  3256f628-e534-4826-9d63-4a8b88782852       660681  Landing Page Submission   \n",
              "\n",
              "      Lead Source Do Not Email Do Not Call  Converted  TotalVisits  \\\n",
              "0      Olark Chat           No          No          0          0.0   \n",
              "1  Organic Search           No          No          0          5.0   \n",
              "2  Direct Traffic           No          No          1          2.0   \n",
              "3  Direct Traffic           No          No          0          1.0   \n",
              "4          Google           No          No          1          2.0   \n",
              "\n",
              "   Total Time Spent on Website  Page Views Per Visit  ...  \\\n",
              "0                            0                   0.0  ...   \n",
              "1                          674                   2.5  ...   \n",
              "2                         1532                   2.0  ...   \n",
              "3                          305                   1.0  ...   \n",
              "4                         1428                   1.0  ...   \n",
              "\n",
              "  Get updates on DM Content    Lead Profile    City  \\\n",
              "0                        No          Select  Select   \n",
              "1                        No          Select  Select   \n",
              "2                        No  Potential Lead  Mumbai   \n",
              "3                        No          Select  Mumbai   \n",
              "4                        No          Select  Mumbai   \n",
              "\n",
              "  Asymmetrique Activity Index Asymmetrique Profile Index  \\\n",
              "0                   02.Medium                  02.Medium   \n",
              "1                   02.Medium                  02.Medium   \n",
              "2                   02.Medium                    01.High   \n",
              "3                   02.Medium                    01.High   \n",
              "4                   02.Medium                    01.High   \n",
              "\n",
              "  Asymmetrique Activity Score Asymmetrique Profile Score  \\\n",
              "0                        15.0                       15.0   \n",
              "1                        15.0                       15.0   \n",
              "2                        14.0                       20.0   \n",
              "3                        13.0                       17.0   \n",
              "4                        15.0                       18.0   \n",
              "\n",
              "  I agree to pay the amount through cheque  \\\n",
              "0                                       No   \n",
              "1                                       No   \n",
              "2                                       No   \n",
              "3                                       No   \n",
              "4                                       No   \n",
              "\n",
              "  A free copy of Mastering The Interview Last Notable Activity  \n",
              "0                                     No              Modified  \n",
              "1                                     No          Email Opened  \n",
              "2                                    Yes          Email Opened  \n",
              "3                                     No              Modified  \n",
              "4                                     No              Modified  \n",
              "\n",
              "[5 rows x 37 columns]"
            ]
          },
          "execution_count": 237,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# for first 5 rows\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 238,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 9240 entries, 0 to 9239\n",
            "Data columns (total 37 columns):\n",
            " #   Column                                         Non-Null Count  Dtype  \n",
            "---  ------                                         --------------  -----  \n",
            " 0   Prospect ID                                    9240 non-null   object \n",
            " 1   Lead Number                                    9240 non-null   int64  \n",
            " 2   Lead Origin                                    9240 non-null   object \n",
            " 3   Lead Source                                    9204 non-null   object \n",
            " 4   Do Not Email                                   9240 non-null   object \n",
            " 5   Do Not Call                                    9240 non-null   object \n",
            " 6   Converted                                      9240 non-null   int64  \n",
            " 7   TotalVisits                                    9103 non-null   float64\n",
            " 8   Total Time Spent on Website                    9240 non-null   int64  \n",
            " 9   Page Views Per Visit                           9103 non-null   float64\n",
            " 10  Last Activity                                  9137 non-null   object \n",
            " 11  Country                                        6779 non-null   object \n",
            " 12  Specialization                                 7802 non-null   object \n",
            " 13  How did you hear about X Education             7033 non-null   object \n",
            " 14  What is your current occupation                6550 non-null   object \n",
            " 15  What matters most to you in choosing a course  6531 non-null   object \n",
            " 16  Search                                         9240 non-null   object \n",
            " 17  Magazine                                       9240 non-null   object \n",
            " 18  Newspaper Article                              9240 non-null   object \n",
            " 19  X Education Forums                             9240 non-null   object \n",
            " 20  Newspaper                                      9240 non-null   object \n",
            " 21  Digital Advertisement                          9240 non-null   object \n",
            " 22  Through Recommendations                        9240 non-null   object \n",
            " 23  Receive More Updates About Our Courses         9240 non-null   object \n",
            " 24  Tags                                           5887 non-null   object \n",
            " 25  Lead Quality                                   4473 non-null   object \n",
            " 26  Update me on Supply Chain Content              9240 non-null   object \n",
            " 27  Get updates on DM Content                      9240 non-null   object \n",
            " 28  Lead Profile                                   6531 non-null   object \n",
            " 29  City                                           7820 non-null   object \n",
            " 30  Asymmetrique Activity Index                    5022 non-null   object \n",
            " 31  Asymmetrique Profile Index                     5022 non-null   object \n",
            " 32  Asymmetrique Activity Score                    5022 non-null   float64\n",
            " 33  Asymmetrique Profile Score                     5022 non-null   float64\n",
            " 34  I agree to pay the amount through cheque       9240 non-null   object \n",
            " 35  A free copy of Mastering The Interview         9240 non-null   object \n",
            " 36  Last Notable Activity                          9240 non-null   object \n",
            "dtypes: float64(4), int64(3), object(30)\n",
            "memory usage: 2.6+ MB\n"
          ]
        }
      ],
      "source": [
        "#for information\n",
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 239,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Lead Number</th>\n",
              "      <th>Converted</th>\n",
              "      <th>TotalVisits</th>\n",
              "      <th>Total Time Spent on Website</th>\n",
              "      <th>Page Views Per Visit</th>\n",
              "      <th>Asymmetrique Activity Score</th>\n",
              "      <th>Asymmetrique Profile Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>9240.000000</td>\n",
              "      <td>9240.000000</td>\n",
              "      <td>9103.000000</td>\n",
              "      <td>9240.000000</td>\n",
              "      <td>9103.000000</td>\n",
              "      <td>5022.000000</td>\n",
              "      <td>5022.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>617188.435606</td>\n",
              "      <td>0.385390</td>\n",
              "      <td>3.445238</td>\n",
              "      <td>487.698268</td>\n",
              "      <td>2.362820</td>\n",
              "      <td>14.306252</td>\n",
              "      <td>16.344883</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>23405.995698</td>\n",
              "      <td>0.486714</td>\n",
              "      <td>4.854853</td>\n",
              "      <td>548.021466</td>\n",
              "      <td>2.161418</td>\n",
              "      <td>1.386694</td>\n",
              "      <td>1.811395</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>579533.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>11.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>596484.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>12.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>14.000000</td>\n",
              "      <td>15.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>615479.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>248.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>14.000000</td>\n",
              "      <td>16.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>637387.250000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>936.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>15.000000</td>\n",
              "      <td>18.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>660737.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>251.000000</td>\n",
              "      <td>2272.000000</td>\n",
              "      <td>55.000000</td>\n",
              "      <td>18.000000</td>\n",
              "      <td>20.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         Lead Number    Converted  TotalVisits  Total Time Spent on Website  \\\n",
              "count    9240.000000  9240.000000  9103.000000                  9240.000000   \n",
              "mean   617188.435606     0.385390     3.445238                   487.698268   \n",
              "std     23405.995698     0.486714     4.854853                   548.021466   \n",
              "min    579533.000000     0.000000     0.000000                     0.000000   \n",
              "25%    596484.500000     0.000000     1.000000                    12.000000   \n",
              "50%    615479.000000     0.000000     3.000000                   248.000000   \n",
              "75%    637387.250000     1.000000     5.000000                   936.000000   \n",
              "max    660737.000000     1.000000   251.000000                  2272.000000   \n",
              "\n",
              "       Page Views Per Visit  Asymmetrique Activity Score  \\\n",
              "count           9103.000000                  5022.000000   \n",
              "mean               2.362820                    14.306252   \n",
              "std                2.161418                     1.386694   \n",
              "min                0.000000                     7.000000   \n",
              "25%                1.000000                    14.000000   \n",
              "50%                2.000000                    14.000000   \n",
              "75%                3.000000                    15.000000   \n",
              "max               55.000000                    18.000000   \n",
              "\n",
              "       Asymmetrique Profile Score  \n",
              "count                 5022.000000  \n",
              "mean                    16.344883  \n",
              "std                      1.811395  \n",
              "min                     11.000000  \n",
              "25%                     15.000000  \n",
              "50%                     16.000000  \n",
              "75%                     18.000000  \n",
              "max                     20.000000  "
            ]
          },
          "execution_count": 239,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#for describe\n",
        "df.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 240,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Prospect ID                                         0\n",
              "Lead Number                                         0\n",
              "Lead Origin                                         0\n",
              "Lead Source                                        36\n",
              "Do Not Email                                        0\n",
              "Do Not Call                                         0\n",
              "Converted                                           0\n",
              "TotalVisits                                       137\n",
              "Total Time Spent on Website                         0\n",
              "Page Views Per Visit                              137\n",
              "Last Activity                                     103\n",
              "Country                                          2461\n",
              "Specialization                                   1438\n",
              "How did you hear about X Education               2207\n",
              "What is your current occupation                  2690\n",
              "What matters most to you in choosing a course    2709\n",
              "Search                                              0\n",
              "Magazine                                            0\n",
              "Newspaper Article                                   0\n",
              "X Education Forums                                  0\n",
              "Newspaper                                           0\n",
              "Digital Advertisement                               0\n",
              "Through Recommendations                             0\n",
              "Receive More Updates About Our Courses              0\n",
              "Tags                                             3353\n",
              "Lead Quality                                     4767\n",
              "Update me on Supply Chain Content                   0\n",
              "Get updates on DM Content                           0\n",
              "Lead Profile                                     2709\n",
              "City                                             1420\n",
              "Asymmetrique Activity Index                      4218\n",
              "Asymmetrique Profile Index                       4218\n",
              "Asymmetrique Activity Score                      4218\n",
              "Asymmetrique Profile Score                       4218\n",
              "I agree to pay the amount through cheque            0\n",
              "A free copy of Mastering The Interview              0\n",
              "Last Notable Activity                               0\n",
              "dtype: int64"
            ]
          },
          "execution_count": 240,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#checking null values\n",
        "df.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "execution_count": 242,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#for duplicates\n",
        "df.duplicated().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Index(['Prospect ID', 'Lead Number', 'Lead Origin', 'Lead Source',\n",
              "       'Do Not Email', 'Do Not Call', 'Converted', 'TotalVisits',\n",
              "       'Total Time Spent on Website', 'Page Views Per Visit', 'Last Activity',\n",
              "       'Country', 'Specialization', 'How did you hear about X Education',\n",
              "       'What is your current occupation',\n",
              "       'What matters most to you in choosing a course', 'Search', 'Magazine',\n",
              "       'Newspaper Article', 'X Education Forums', 'Newspaper',\n",
              "       'Digital Advertisement', 'Through Recommendations',\n",
              "       'Receive More Updates About Our Courses', 'Tags', 'Lead Quality',\n",
              "       'Update me on Supply Chain Content', 'Get updates on DM Content',\n",
              "       'Lead Profile', 'City', 'Asymmetrique Activity Index',\n",
              "       'Asymmetrique Profile Index', 'Asymmetrique Activity Score',\n",
              "       'Asymmetrique Profile Score',\n",
              "       'I agree to pay the amount through cheque',\n",
              "       'A free copy of Mastering The Interview', 'Last Notable Activity'],\n",
              "      dtype='object')"
            ]
          },
          "execution_count": 243,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# for columns\n",
        "df.columns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 246,
      "metadata": {},
      "outputs": [],
      "source": [
        "## Normalize column names: remove leading/trailing spaces, convert to lowercase, and replace spaces with underscores\n",
        "df.columns = df.columns.str.strip().str.lower().str.replace(\" \", \"_\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 247,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "execution_count": 247,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#for duplicates\n",
        "df.duplicated().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 248,
      "metadata": {},
      "outputs": [],
      "source": [
        "#  Drop ID columns because these are unique columns\n",
        "df.drop(['prospect_id', 'lead_number'], axis=1, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 249,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1281"
            ]
          },
          "execution_count": 249,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.duplicated().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 250,
      "metadata": {},
      "outputs": [],
      "source": [
        "#  Replace 'Select' and empty strings with NaN\n",
        "df.replace([\"Select\", \"\", None], np.nan, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 251,
      "metadata": {},
      "outputs": [],
      "source": [
        "#  Convert binary columns\n",
        "binary_cols = [\n",
        "    \"do_not_email\", \"do_not_call\", \"search\", \"magazine\", \"newspaper_article\",\n",
        "    \"newspaper\", \"digital_advertisement\", \"through_recommendations\",\n",
        "    \"receive_more_updates_about_our_courses\", \"get_updates_on_dm_content\",\n",
        "    \"i_agree_to_pay_the_amount_through_cheque\", \"a_free_copy_of_mastering_the_interview\"\n",
        "]\n",
        "binary_map = {\"Yes\": 1, \"No\": 0}\n",
        "for col in binary_cols:\n",
        "    if col in df.columns:\n",
        "        df[col] = df[col].map(binary_map)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 252,
      "metadata": {},
      "outputs": [],
      "source": [
        "#  Define features and target\n",
        "X = df.drop(columns=[\"converted\"])\n",
        "y = df[\"converted\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 253,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "📊 Class distribution:\n",
            "converted\n",
            "0    5679\n",
            "1    3561\n",
            "Name: count, dtype: int64\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Check class imbalance\n",
        "print(\"\\n📊 Class distribution:\")\n",
        "print(y.value_counts())\n",
        "sns.countplot(x=y)\n",
        "plt.title(\"Class Balance: Converted (0 vs 1)\")\n",
        "plt.show()\n",
        "\n",
        "# Apply SMOTE only after train/test split\n",
        "X_train_raw, X_test_raw, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 254,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "📊 Class distribution before SMOTE:\n",
            "converted\n",
            "0    4534\n",
            "1    2858\n",
            "Name: count, dtype: int64\n",
            "\n",
            "📏 Shape before SMOTE:\n",
            "X_train_raw: (7392, 34)\n",
            "y_train: (7392,)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# 📊 Class distribution before SMOTE\n",
        "print(\"\\n📊 Class distribution before SMOTE:\")\n",
        "print(y_train.value_counts())\n",
        "\n",
        "# 🔢 Shape before SMOTE\n",
        "print(f\"\\n📏 Shape before SMOTE:\\nX_train_raw: {X_train_raw.shape}\\ny_train: {y_train.shape}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 255,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Function to build and save a preprocessing pipeline\n",
        "def build_preprocessing_pipeline(X, ordinal_features, ordinal_mapping, pipeline_path=\"preprocess.pkl\"):\n",
        "    # Identify numeric and categorical columns from input DataFrame X\n",
        "    numeric_features = X.select_dtypes(include=['number']).columns.tolist()\n",
        "    categorical_features = X.select_dtypes(include=['object', 'category']).columns.tolist()\n",
        "    # Ensure only those ordinal features that actually exist in the data are used\n",
        "    ordinal_features = list(set(ordinal_features) & set(categorical_features))\n",
        "    # Remove ordinal features from the general categorical list\n",
        "    categorical_features = list(set(categorical_features) - set(ordinal_features))\n",
        "    # Numeric preprocessing: impute missing values with median, then scale to [0, 1]\n",
        "    numeric_pipeline = Pipeline([\n",
        "        ('imputer', SimpleImputer(strategy='median')),\n",
        "        ('scaler', MinMaxScaler()),\n",
        "        \n",
        "    ])\n",
        "    # Categorical preprocessing: impute missing values with the most frequent category, then one-hot encode\n",
        "    categorical_pipeline = Pipeline([\n",
        "        ('imputer', SimpleImputer(strategy='most_frequent')),\n",
        "        ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n",
        "    ])\n",
        "     # Ordinal preprocessing: impute with most frequent value, then apply ordinal encoding using provided mappings\n",
        "    ordinal_pipeline = Pipeline([\n",
        "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
        "    (\"ordinal\", OrdinalEncoder(categories=ordinal_mapping))\n",
        "    ])\n",
        "    # Combine all sub-pipelines using ColumnTransformer\n",
        "    preprocessor = ColumnTransformer([\n",
        "    (\"num\", numeric_pipeline, numeric_features),\n",
        "    (\"cat\", categorical_pipeline, categorical_features),\n",
        "    (\"ord\", ordinal_pipeline, ordinal_features)\n",
        "    ])\n",
        "\n",
        "    # Save the entire preprocessing pipeline to disk for reuse\n",
        "    joblib.dump(preprocessor, pipeline_path)\n",
        "    print(f\"✅ Preprocessing pipeline saved at: {pipeline_path}\")\n",
        "    return preprocessor, numeric_features, categorical_features\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 256,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Preprocessing pipeline saved at: preprocess.pkl\n",
            "\n",
            "🔄 Applying SMOTE to balance classes...\n",
            "\n",
            "✅ Class distribution after SMOTE:\n",
            "converted\n",
            "0    4534\n",
            "1    4534\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Define ordinal features and their order\n",
        "ordinal_features = ['asymmetrique_activity_index', 'asymmetrique_profile_index']\n",
        "ordinal_mapping = [['03.Low', '02.Medium', '01.High']] * len(ordinal_features)\n",
        "\n",
        "# Call the preprocessing function to build and save the pipeline\n",
        "preprocessor, num_cols, cat_cols = build_preprocessing_pipeline(\n",
        "    X_train_raw, ordinal_features, ordinal_mapping\n",
        ")\n",
        "\n",
        "# Fit the preprocessor on training data and transform it\n",
        "X_train_processed = preprocessor.fit_transform(X_train_raw)\n",
        "# Apply the same transformation to test data without fitting again\n",
        "X_test_processed = preprocessor.transform(X_test_raw)\n",
        "\n",
        "# Apply SMOTE to handle class imbalance in the training data\n",
        "print(\"\\n🔄 Applying SMOTE to balance classes...\")\n",
        "smote = SMOTE(random_state=42)\n",
        "X_train_balanced, y_train_balanced = smote.fit_resample(X_train_processed, y_train)\n",
        "\n",
        "# Output the new class distribution after balancing\n",
        "print(\"\\n✅ Class distribution after SMOTE:\")\n",
        "print(pd.Series(y_train_balanced).value_counts())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 257,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "🔢 Shape after SMOTE:\n",
            "X_train_balanced: (9068, 188)\n",
            "y_train_balanced: (9068,)\n"
          ]
        }
      ],
      "source": [
        "# Check shape after SMOTE\n",
        "print(f\"\\n🔢 Shape after SMOTE:\\nX_train_balanced: {X_train_balanced.shape}\\ny_train_balanced: {y_train_balanced.shape}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 228,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Function to transform the data using a fitted preprocessor and return a DataFrame with proper column names\n",
        "def transform_data(X, preprocessor, numeric_features, categorical_features, ordinal_features=None):\n",
        "    # Apply the preprocessing pipeline: fit and transform the input data\n",
        "    processed = preprocessor.fit_transform(X)\n",
        "    \n",
        "    try:\n",
        "        # Extract the one-hot encoder object from the 'cat' pipeline\n",
        "        ohe = preprocessor.named_transformers_['cat'].named_steps['onehot']\n",
        "        \n",
        "        # Get the new feature names created by one-hot encoding the categorical variables\n",
        "        cat_feature_names = ohe.get_feature_names_out(categorical_features)\n",
        "\n",
        "        # Use ordinal feature names as-is, since ordinal encoding doesn’t create new feature names\n",
        "        if ordinal_features:\n",
        "            ord_feature_names = ordinal_features\n",
        "        else:\n",
        "            ord_feature_names = []\n",
        "\n",
        "        # Combine all column names: numeric, one-hot encoded categorical, and ordinal\n",
        "        all_columns = numeric_features + list(cat_feature_names) + ord_feature_names\n",
        "\n",
        "        # Return the transformed data as a DataFrame with appropriate column names\n",
        "        return pd.DataFrame(processed, columns=all_columns)\n",
        "\n",
        "    except Exception as e:\n",
        "        # Handle any error (e.g., when feature names can't be extracted) and return unnamed DataFrame\n",
        "        print(f\"⚠️ Could not extract feature names: {e}\")\n",
        "        return pd.DataFrame(processed)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 229,
      "metadata": {
        "id": "wCMuuheYrXF9"
      },
      "outputs": [],
      "source": [
        "# Function to evaluate classification model performance\n",
        "def evaluate_classification_model(y_true, y_pred, y_proba):\n",
        "    return {\n",
        "        # Overall accuracy: how many predictions were correct\n",
        "        \"accuracy\": accuracy_score(y_true, y_pred),\n",
        "\n",
        "        # Precision: of the predicted positives, how many are actually positive\n",
        "        \"precision\": precision_score(y_true, y_pred, zero_division=0),\n",
        "\n",
        "        # Recall: of all actual positives, how many did we correctly identify\n",
        "        \"recall\": recall_score(y_true, y_pred, zero_division=0),\n",
        "\n",
        "        # F1-score: harmonic mean of precision and recall (useful for imbalanced datasets)\n",
        "        \"f1\": f1_score(y_true, y_pred, zero_division=0),\n",
        "\n",
        "        # ROC-AUC: area under the Receiver Operating Characteristic curve (requires probabilities)\n",
        "        \"roc_auc\": roc_auc_score(y_true, y_proba)\n",
        "    }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train multiple models, log results to MLflow, and generate SHAP explanations\n",
        "def train_log_and_shap(models, X_train, y_train, X_val, y_val,\n",
        "                       preprocessor, feature_names,\n",
        "                       save_dir=\"saved_models\", shap_dir=\"shap_outputs\"):\n",
        "    \n",
        "    # Create directories if they don't exist\n",
        "    os.makedirs(save_dir, exist_ok=True)\n",
        "    os.makedirs(shap_dir, exist_ok=True)\n",
        "\n",
        "    # Set MLflow tracking server and experiment name\n",
        "    mlflow.set_tracking_uri(\"http://localhost:5000\")\n",
        "    mlflow.set_experiment(\"Lead Conversion Prediction\")\n",
        "\n",
        "    results = []       # Stores evaluation metrics for all models\n",
        "    best_models = {}   # Stores best trained model per algorithm\n",
        "\n",
        "    # Iterate over each model and its hyperparameters\n",
        "    for name, model_info in models.items():\n",
        "        print(f\"\\n🔧 Training: {name}\")\n",
        "\n",
        "        # Perform grid search with 3-fold cross-validation, optimizing for F1-score\n",
        "        grid = GridSearchCV(model_info['model'], model_info['params'],\n",
        "                            cv=3, scoring='f1', n_jobs=-1)\n",
        "        grid.fit(X_train, y_train)\n",
        "\n",
        "        # Predict on validation set\n",
        "        y_pred = grid.predict(X_val)\n",
        "        # If model supports probabilities, get them for ROC-AUC\n",
        "        y_proba = grid.predict_proba(X_val)[:, 1] if hasattr(grid, \"predict_proba\") else y_pred\n",
        "\n",
        "        #  Evaluate the model\n",
        "        metrics = evaluate_classification_model(y_val, y_pred, y_proba)\n",
        "        results.append({\"model\": name, \"best_params\": grid.best_params_, **metrics})\n",
        "        best_models[name] = grid.best_estimator_\n",
        "\n",
        "        #  Save the best model to disk\n",
        "        model_path = os.path.join(save_dir, f\"{name}_best_model.pkl\")\n",
        "        joblib.dump(grid.best_estimator_, model_path)\n",
        "\n",
        "        # Log to MLflow\n",
        "        with mlflow.start_run(run_name=name) as run:\n",
        "            mlflow.log_params(grid.best_params_)\n",
        "            mlflow.log_metrics(metrics)\n",
        "            mlflow.sklearn.log_model(grid.best_estimator_, \"model\")\n",
        "\n",
        "            #  Generate SHAP explanations\n",
        "            try:\n",
        "                # Convert input back to DataFrame or Prepare the validation data as DataFrame  (required for SHAP)\n",
        "                X_val_df = pd.DataFrame(X_val, columns=feature_names)\n",
        "                fitted_model = grid.best_estimator_\n",
        "\n",
        "                # Use appropriate SHAP explainer based on model type\n",
        "                if isinstance(fitted_model, (DecisionTreeClassifier, RandomForestClassifier, XGBClassifier)):\n",
        "                    explainer = shap.TreeExplainer(fitted_model)\n",
        "                    shap_values = explainer.shap_values(X_val_df)\n",
        "                elif isinstance(fitted_model, LogisticRegression):\n",
        "                    explainer = shap.Explainer(fitted_model, X_val_df)\n",
        "                    shap_values = explainer(X_val_df)\n",
        "                else:\n",
        "                    print(f\"⚠️ SHAP skipped for {name}: Unsupported model type.\")\n",
        "                    continue\n",
        "\n",
        "                # Save SHAP summary plot to disk\n",
        "                shap_path = os.path.join(shap_dir, f\"{name}_shap_summary.png\")\n",
        "                plt.figure()\n",
        "                shap.summary_plot(shap_values, X_val_df, show=False)\n",
        "                plt.savefig(shap_path, bbox_inches=\"tight\")\n",
        "                plt.close()\n",
        "\n",
        "                # Log SHAP plot to MLflow\n",
        "                mlflow.log_artifact(shap_path, artifact_path=\"shap_plots\")\n",
        "                print(f\"✅ SHAP saved & logged: {shap_path}\")\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"⚠️ SHAP failed for {name}: {e}\")\n",
        "\n",
        "    #  Compile all metrics into a summary DataFrame\n",
        "    results_df = pd.DataFrame(results)\n",
        "    print(\"\\n📊 All Model Validation Metrics:\")\n",
        "    print(results_df[[\"model\", \"accuracy\", \"precision\", \"recall\", \"f1\", \"roc_auc\"]].to_string(index=False))\n",
        "\n",
        "    return results_df, best_models\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save, retrain, and register the best-performing model using MLflow\n",
        "def save_and_register_best_model_pipeline(results_df, best_models,\n",
        "                                          X_train_val, y_train_val,       # Full dataset the \"best model\" should be retrained on (typically train + validation combined).\n",
        "                                          preprocessor,\n",
        "                                          save_dir=\"saved_models\"):\n",
        "\n",
        "    # 📁 Ensure save directory exists\n",
        "    os.makedirs(save_dir, exist_ok=True)   #Directory where the final pipeline .pkl file will be saved.\n",
        "\n",
        "    # 🔍 Step 1: Identify the best model based on ROC AUC (descending)\n",
        "    best_model_name = results_df.sort_values(by=\"roc_auc\", ascending=False).iloc[0][\"model\"]\n",
        "    best_model = best_models[best_model_name]\n",
        "    print(f\"\\n🏆 Best model selected: {best_model_name}\")\n",
        "\n",
        "    # 🔁 Step 2: Retrain the best model on full training + validation dataset\n",
        "    best_model.fit(X_train_val, y_train_val)\n",
        "\n",
        "    # 🛠️ Step 3: Build a complete pipeline with preprocessing and model\n",
        "    full_pipeline = Pipeline([\n",
        "        (\"preprocessing\", preprocessor),\n",
        "        (\"model\", best_model)\n",
        "    ])\n",
        "\n",
        "    # 💾 Step 4: Save the final pipeline locally as a .pkl file for local backup or use outside MLflow.\n",
        "    model_path = os.path.join(save_dir, f\"final_{best_model_name}_pipeline.pkl\")\n",
        "    joblib.dump(full_pipeline, model_path)\n",
        "    print(f\"✅ Final pipeline saved at: {model_path}\")\n",
        "\n",
        "    # 🧪 Step 5: Log and register the model in MLflow Model Registry\n",
        "    mlflow.set_tracking_uri(\"http://localhost:5000\")  # Local MLflow tracking server\n",
        "    mlflow.set_experiment(\"Lead Conversion Prediction\")  # Set the experiment\n",
        "    client = MlflowClient()  # MLflow client for advanced registry actions\n",
        "\n",
        "    with mlflow.start_run(run_name=f\"Final_{best_model_name}\") as run:\n",
        "        run_id = run.info.run_id\n",
        "\n",
        "        # ✅ Log the full pipeline with sklearn flavor\n",
        "        mlflow.sklearn.log_model(full_pipeline, artifact_path=\"model\")\n",
        "\n",
        "        print(f\"🔁 Registering model to MLflow Model Registry: {best_model_name}\")\n",
        "        model_uri = f\"runs:/{run_id}/model\"\n",
        "\n",
        "        # 🔐 Register the model under the given name\n",
        "        registered_model = mlflow.register_model(\n",
        "            model_uri=model_uri,\n",
        "            name=best_model_name\n",
        "        )\n",
        "        # 🕒 Wait for model to fully register (prevents race conditions)\n",
        "        time.sleep(10)\n",
        "        # ✅ Transition model version to \"Production\" stage\n",
        "        client.transition_model_version_stage(\n",
        "            name=best_model_name,\n",
        "            version=registered_model.version,\n",
        "            stage=\"Production\",\n",
        "            archive_existing_versions=True  # Archive any previous version\n",
        "        )\n",
        "        print(f\"✅ Model '{best_model_name}' version {registered_model.version} moved to 'Production'.\")\n",
        "\n",
        "        # 🏷️ Optionally assign alias \"champion\" to this production version\n",
        "        try:\n",
        "            client.set_model_version_alias(\n",
        "                name=best_model_name,\n",
        "                version=registered_model.version,\n",
        "                alias=\"champion\"\n",
        "            )\n",
        "            print(f\"🏷️ Alias 'champion' assigned to version {registered_model.version}.\")\n",
        "        except Exception as e:\n",
        "            print(f\"⚠️ Unable to set alias 'champion': {e}\")\n",
        "\n",
        "        # 🔗 Provide direct link to MLflow run\n",
        "        print(f\"🏃 View run: http://localhost:5000/#/experiments/{run.info.experiment_id}/runs/{run_id}\")\n",
        "\n",
        "    # ✅ Return pipeline, model name, and file path for reuse\n",
        "    return full_pipeline, best_model_name, model_path\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 232,
      "metadata": {
        "id": "uzFlC5AqvoaT"
      },
      "outputs": [],
      "source": [
        "# Reload a saved pipeline, retrain it on full data, evaluate, and save again\n",
        "def retrain_loaded_pipeline(model_path, processed, y, save_path=\"saved_models/final_lead_model_retrained.pkl\"):\n",
        "    \n",
        "    # 📦 Load the full pipeline (including preprocessing and model)\n",
        "    print(f\"\\n📦 Loading pipeline from: {model_path}\")\n",
        "    model = joblib.load(model_path)\n",
        "\n",
        "    # 🔁 Retrain model on the full dataset\n",
        "    model.fit(processed, y)\n",
        "\n",
        "    # 🔮 Make predictions on the same data\n",
        "    preds = model.predict(processed)\n",
        "    # Get prediction probabilities if available (for ROC AUC)\n",
        "    proba = model.predict_proba(processed)[:, 1] if hasattr(model, 'predict_proba') else None\n",
        "\n",
        "    # 🧪 Compute standard classification metrics\n",
        "    accuracy  = accuracy_score(y, preds)\n",
        "    precision = precision_score(y, preds, zero_division=0)\n",
        "    recall    = recall_score(y, preds, zero_division=0)\n",
        "    f1        = f1_score(y, preds, zero_division=0)\n",
        "    roc_auc   = roc_auc_score(y, proba) if proba is not None else None\n",
        "\n",
        "    # 📊 Display metrics to user\n",
        "    print(\"\\n📊 Metrics after retraining on full data:\")\n",
        "    print(f\"Accuracy  : {accuracy:.4f}\")\n",
        "    print(f\"Precision : {precision:.4f}\")\n",
        "    print(f\"Recall    : {recall:.4f}\")\n",
        "    print(f\"F1 Score  : {f1:.4f}\")\n",
        "    if roc_auc is not None:\n",
        "        print(f\"ROC AUC   : {roc_auc:.4f}\")\n",
        "\n",
        "    # 💾 Save the retrained pipeline back to disk\n",
        "    joblib.dump(model, save_path)\n",
        "    print(f\"\\n✅ Retrained model saved at: {save_path}\")\n",
        "\n",
        "    # 📤 Return evaluation metrics in a dictionary\n",
        "    return {\n",
        "        \"accuracy\": accuracy,\n",
        "        \"precision\": precision,\n",
        "        \"recall\": recall,\n",
        "        \"f1_score\": f1,\n",
        "        \"roc_auc\": roc_auc\n",
        "    }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 233,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Main driver function to execute the full ML pipeline from preprocessing to model registration\n",
        "def run_pipeline(X, y, models):\n",
        "    \"\"\"\n",
        "    Main function to:\n",
        "    - Build preprocessing pipeline\n",
        "    - Transform data\n",
        "    - Split data into train/val/test\n",
        "    - Train, evaluate, log, and explain models with SHAP\n",
        "    - Save and register the best model pipeline\n",
        "\n",
        "    Parameters:\n",
        "        X (DataFrame): Feature set\n",
        "        y (Series): Target labels\n",
        "        models (dict): Dictionary containing model objects and their hyperparameter grids\n",
        "\n",
        "    Returns:\n",
        "        full_pipeline (Pipeline): Final retrained pipeline with preprocessing + best model\n",
        "        final_model_path (str): Path where the final model is saved\n",
        "        best_model_name (str): Name of the best performing model\n",
        "        results_df (DataFrame): Evaluation metrics for all models\n",
        "    \"\"\"\n",
        "\n",
        "    # ✅ Step 1: Build preprocessing pipeline (numeric, categorical, ordinal)\n",
        "    preprocessor, numeric_features, categorical_features = build_preprocessing_pipeline(\n",
        "        X, ordinal_features, ordinal_mapping\n",
        "    )\n",
        "\n",
        "    # ✅ Step 2: Transform the data using the preprocessor\n",
        "    processed = transform_data(X, preprocessor, numeric_features, categorical_features)\n",
        "    feature_names = preprocessor.get_feature_names_out()  # Needed for SHAP visualizations\n",
        "\n",
        "    # ✅ Step 3: Split the processed data into Train (60%) / Val (20%) / Test (20%)\n",
        "    X_temp, X_test, y_temp, y_test = train_test_split(\n",
        "        processed, y, test_size=0.2, random_state=42, stratify=y\n",
        "    )\n",
        "    X_train, X_val, y_train, y_val = train_test_split(\n",
        "        X_temp, y_temp, test_size=0.25, random_state=42, stratify=y_temp\n",
        "    )\n",
        "\n",
        "    # ✅ Step 4: Train models, evaluate, log metrics and SHAP explanations via MLflow\n",
        "    results_df, best_models = train_log_and_shap(\n",
        "        models, X_train, y_train, X_val, y_val, preprocessor, feature_names\n",
        "    )\n",
        "\n",
        "    # ✅ Step 5: Retrain best model on full training + validation set, save and register pipeline\n",
        "    full_pipeline, best_model_name, final_model_path = save_and_register_best_model_pipeline(\n",
        "        results_df,\n",
        "        best_models,\n",
        "        pd.concat([pd.DataFrame(X_train), pd.DataFrame(X_val)], axis=0),\n",
        "        pd.concat([y_train, y_val], axis=0),\n",
        "        preprocessor\n",
        "    )\n",
        "\n",
        "    # ✅ Final output info\n",
        "    print(f\"\\n📦 Final model pipeline: {best_model_name}\")\n",
        "    print(f\"📁 Saved pipeline at: {final_model_path}\")\n",
        "\n",
        "    return full_pipeline, final_model_path, best_model_name, results_df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 234,
      "metadata": {
        "id": "K2t2X4lBxQEX"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Preprocessing pipeline saved at: preprocess.pkl\n",
            "⚠️ Could not extract feature names: Shape of passed values is (9240, 197), indices imply (9240, 195)\n",
            "\n",
            "🔧 Training: LogisticRegression\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025/07/20 08:11:44 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
            "2025/07/20 08:11:48 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ SHAP saved & logged: shap_outputs\\LogisticRegression_shap_summary.png\n",
            "🏃 View run LogisticRegression at: http://localhost:5000/#/experiments/952538402659340950/runs/6e1dd7dfbb8148adb7717a29626bdbc0\n",
            "🧪 View experiment at: http://localhost:5000/#/experiments/952538402659340950\n",
            "\n",
            "🔧 Training: DecisionTree\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025/07/20 08:11:50 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
            "2025/07/20 08:11:54 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ SHAP saved & logged: shap_outputs\\DecisionTree_shap_summary.png\n",
            "🏃 View run DecisionTree at: http://localhost:5000/#/experiments/952538402659340950/runs/199ba5a4a1ce47019062a2e7843ae088\n",
            "🧪 View experiment at: http://localhost:5000/#/experiments/952538402659340950\n",
            "\n",
            "🔧 Training: RandomForest\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025/07/20 08:12:02 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
            "2025/07/20 08:12:06 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ SHAP saved & logged: shap_outputs\\RandomForest_shap_summary.png\n",
            "🏃 View run RandomForest at: http://localhost:5000/#/experiments/952538402659340950/runs/42d1a277ce5c4edc8dfe2e10c091c877\n",
            "🧪 View experiment at: http://localhost:5000/#/experiments/952538402659340950\n",
            "\n",
            "🔧 Training: XGBoost\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025/07/20 08:20:20 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
            "2025/07/20 08:20:24 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ SHAP saved & logged: shap_outputs\\XGBoost_shap_summary.png\n",
            "🏃 View run XGBoost at: http://localhost:5000/#/experiments/952538402659340950/runs/d8759b5290d744ed94521a2d0028c2a2\n",
            "🧪 View experiment at: http://localhost:5000/#/experiments/952538402659340950\n",
            "\n",
            "📊 All Model Validation Metrics:\n",
            "             model  accuracy  precision   recall       f1  roc_auc\n",
            "LogisticRegression  0.920455   0.911208 0.879213 0.894925 0.967847\n",
            "      DecisionTree  0.895022   0.886567 0.834270 0.859624 0.922138\n",
            "      RandomForest  0.920455   0.906475 0.884831 0.895522 0.971315\n",
            "           XGBoost  0.926948   0.908062 0.901685 0.904863 0.972659\n",
            "\n",
            "🏆 Best model selected: XGBoost\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025/07/20 08:20:25 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Final pipeline saved at: saved_models\\final_XGBoost_pipeline.pkl\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025/07/20 08:20:28 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
            "Registered model 'XGBoost' already exists. Creating a new version of this model...\n",
            "2025/07/20 08:20:29 WARNING mlflow.tracking._model_registry.fluent: Run with id db8bd4b0f56745ea9323dbe3a3d21aa0 has no artifacts at artifact path 'model', registering model based on models:/m-4876db536cfa4934a3d5703013159ed1 instead\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔁 Registering model to MLflow Model Registry: XGBoost\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025/07/20 08:20:29 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: XGBoost, version 4\n",
            "Created version '4' of model 'XGBoost'.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Model 'XGBoost' version 4 moved to 'Production'.\n",
            "⚠️ Unable to set alias 'champion': 'MlflowClient' object has no attribute 'set_model_version_alias'\n",
            "🏃 View run: http://localhost:5000/#/experiments/952538402659340950/runs/db8bd4b0f56745ea9323dbe3a3d21aa0\n",
            "🏃 View run Final_XGBoost at: http://localhost:5000/#/experiments/952538402659340950/runs/db8bd4b0f56745ea9323dbe3a3d21aa0\n",
            "🧪 View experiment at: http://localhost:5000/#/experiments/952538402659340950\n",
            "\n",
            "📦 Final model pipeline: XGBoost\n",
            "📁 Saved pipeline at: saved_models\\final_XGBoost_pipeline.pkl\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(Pipeline(steps=[('preprocessing',\n",
              "                  ColumnTransformer(transformers=[('num',\n",
              "                                                   Pipeline(steps=[('imputer',\n",
              "                                                                    SimpleImputer(strategy='median')),\n",
              "                                                                   ('scaler',\n",
              "                                                                    MinMaxScaler())]),\n",
              "                                                   ['do_not_email',\n",
              "                                                    'do_not_call', 'totalvisits',\n",
              "                                                    'total_time_spent_on_website',\n",
              "                                                    'page_views_per_visit',\n",
              "                                                    'search', 'magazine',\n",
              "                                                    'newspaper_article',\n",
              "                                                    'newspaper',\n",
              "                                                    'digital_advertisement',\n",
              "                                                    'through_recomme...\n",
              "                                feature_types=None, gamma=None, gpu_id=None,\n",
              "                                grow_policy=None, importance_type=None,\n",
              "                                interaction_constraints=None, learning_rate=None,\n",
              "                                max_bin=None, max_cat_threshold=None,\n",
              "                                max_cat_to_onehot=None, max_delta_step=None,\n",
              "                                max_depth=3, max_leaves=None,\n",
              "                                min_child_weight=None, missing=nan,\n",
              "                                monotone_constraints=None, n_estimators=100,\n",
              "                                n_jobs=None, num_parallel_tree=None,\n",
              "                                predictor=None, random_state=42, ...))]),\n",
              " 'saved_models\\\\final_XGBoost_pipeline.pkl',\n",
              " 'XGBoost',\n",
              "                 model                                best_params  accuracy  \\\n",
              " 0  LogisticRegression                                  {'C': 10}  0.920455   \n",
              " 1        DecisionTree  {'max_depth': 10, 'min_samples_split': 5}  0.895022   \n",
              " 2        RandomForest   {'max_depth': None, 'n_estimators': 200}  0.920455   \n",
              " 3             XGBoost      {'max_depth': 3, 'n_estimators': 100}  0.926948   \n",
              " \n",
              "    precision    recall        f1   roc_auc  \n",
              " 0   0.911208  0.879213  0.894925  0.967847  \n",
              " 1   0.886567  0.834270  0.859624  0.922138  \n",
              " 2   0.906475  0.884831  0.895522  0.971315  \n",
              " 3   0.908062  0.901685  0.904863  0.972659  )"
            ]
          },
          "execution_count": 234,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 0 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 0 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# 📦 Classification Models and Hyperparameter Grids\n",
        "models = {\n",
        "    # 🔹 Logistic Regression with regularization strength tuning\n",
        "    'LogisticRegression': {\n",
        "        'model': LogisticRegression(solver='liblinear', random_state=42),\n",
        "        'params': {'C': [0.1, 1, 10]}  # C is the inverse of regularization strength\n",
        "    },\n",
        "\n",
        "    # 🌳 Decision Tree with different depths and splits\n",
        "    'DecisionTree': {\n",
        "        'model': DecisionTreeClassifier(random_state=42),\n",
        "        'params': {\n",
        "            'max_depth': [5, 10, None],         # Controls tree depth\n",
        "            'min_samples_split': [2, 5]         # Minimum samples to split a node\n",
        "        }\n",
        "    },\n",
        "\n",
        "    # 🌲 Random Forest with varying number of trees and depths\n",
        "    'RandomForest': {\n",
        "        'model': RandomForestClassifier(random_state=42),\n",
        "        'params': {\n",
        "            'n_estimators': [100, 200],         # Number of trees in the forest\n",
        "            'max_depth': [None, 10]             # Max depth for each tree\n",
        "        }\n",
        "    },\n",
        "\n",
        "    # ⚡ XGBoost with different tree configurations\n",
        "    'XGBoost': {\n",
        "        'model': XGBClassifier(\n",
        "            random_state=42, \n",
        "            verbosity=0,               # Suppress training logs\n",
        "            use_label_encoder=False    # Avoid warning in newer versions\n",
        "        ),\n",
        "        'params': {\n",
        "            'n_estimators': [100, 200],         # Number of boosting rounds\n",
        "            'max_depth': [3, 6]                 # Depth of each tree\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "# 🚀 Run the full ML pipeline: preprocessing, training, SHAP, MLflow logging, and registration\n",
        "run_pipeline(X, y, models)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def load_and_predict_from_registry(model_name, stage, X_test):\n",
        "    \"\"\"\n",
        "    Loads a scikit-learn pipeline from MLflow Model Registry and makes predictions.\n",
        "\n",
        "    Args:\n",
        "        model_name (str): Name of the registered model in MLflow.\n",
        "        stage (str): Stage to load from (e.g., \"Production\", \"Staging\", or \"None\").\n",
        "        X_test (pd.DataFrame): Test dataset (raw, unprocessed).\n",
        "\n",
        "    Returns:\n",
        "        np.array: Model predictions\n",
        "    \"\"\"\n",
        "    # ✅ Construct model URI\n",
        "    model_uri = f\"models:/{model_name}/{stage}\"\n",
        "\n",
        "    # ✅ Load the pipeline from MLflow\n",
        "    print(f\"📦 Loading model pipeline from MLflow: {model_uri}\")\n",
        "    loaded_pipeline = mlflow.sklearn.load_model(model_uri)\n",
        "\n",
        "    # ✅ Make predictions\n",
        "    predictions = loaded_pipeline.predict(X_test)\n",
        "    print(f\"✅ Predictions complete. Example: {predictions[:5]}\")\n",
        "    \n",
        "    return predictions\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 189,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "📦 Loading model pipeline from MLflow: models:/XGBoost/Production\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading artifacts: 100%|██████████| 5/5 [00:02<00:00,  2.31it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Predictions complete. Example: [1 0 0 0 0]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "model_name = \"XGBoost\"  # or whatever your model name is\n",
        "stage = \"Production\"  # or \"champion\", \"Staging\", etc.\n",
        "\n",
        "y_pred = load_and_predict_from_registry(model_name, stage, X_test_raw)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Loading and Prediction from mlflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Will load XGBoost version 3 (stage/alias: 'Production')\n",
            "📦 Loading from models:/XGBoost/Production\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading artifacts: 100%|██████████| 5/5 [00:02<00:00,  2.38it/s] "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Predictions complete. Example: [1 0 0 0 0]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "#ploading and predicting model fro mlflow automatically\n",
        "def get_latest_production_model_name(stage=\"Production\", alias=None):\n",
        "    \"\"\"\n",
        "    Finds the latest-registered model name in a given MLflow stage or alias.\n",
        "    Args:\n",
        "        stage (str): MLflow stage (\"Production\", \"Staging\", etc).\n",
        "        alias (str): MLflow alias (e.g. \"champion\", optional).\n",
        "    Returns:\n",
        "        str: model_name\n",
        "    \"\"\"\n",
        "    client = MlflowClient()\n",
        "    registered = client.search_registered_models()\n",
        "    if not registered:\n",
        "        raise RuntimeError(\"No models registered in MLflow!\")\n",
        "\n",
        "    # Candidates = list of (model_name, version, timestamp)\n",
        "    candidates = []\n",
        "    for m in registered:\n",
        "        for lv in m.latest_versions:\n",
        "            # Choose model by alias (if provided and MLflow>=2.3) or by stage\n",
        "            if alias:\n",
        "                aliases = getattr(lv, 'aliases', [])\n",
        "                if alias in aliases:\n",
        "                    candidates.append((m.name, lv.version, lv.creation_timestamp))\n",
        "            else:\n",
        "                if lv.current_stage == stage:\n",
        "                    candidates.append((m.name, lv.version, lv.creation_timestamp))\n",
        "\n",
        "    if not candidates:\n",
        "        raise ValueError(f\"No model found in MLflow registry for stage='{stage}' alias='{alias}'\")\n",
        "\n",
        "    # Sort by creation time descending (latest first)\n",
        "    candidates.sort(key=lambda t: t[2], reverse=True)\n",
        "    chosen_model = candidates[0][0]\n",
        "    print(f\"✅ Will load {chosen_model} version {candidates[0][1]} (stage/alias: '{alias or stage}')\")\n",
        "    return chosen_model\n",
        "\n",
        "def load_and_predict_from_registry_auto(X_test, stage=\"Production\", alias=None):\n",
        "    \"\"\"\n",
        "    Loads the latest pipeline from MLflow given a stage/alias, predicts on X_test.\n",
        "    Args:\n",
        "        X_test : raw test DataFrame\n",
        "        stage  : MLflow stage (default \"Production\"), ignored if alias given\n",
        "        alias  : MLflow alias (e.g. \"champion\") if using version aliasing\n",
        "    Returns:\n",
        "        np.array: Model predictions\n",
        "    \"\"\"\n",
        "    model_name = get_latest_production_model_name(stage=stage, alias=alias)\n",
        "    model_uri = f\"models:/{model_name}/{alias or stage}\"\n",
        "    print(f\"📦 Loading from {model_uri}\")\n",
        "    loaded_pipeline = mlflow.sklearn.load_model(model_uri)\n",
        "    predictions = loaded_pipeline.predict(X_test)\n",
        "    print(f\"✅ Predictions complete. Example: {predictions[:5]}\")\n",
        "    return predictions\n",
        "\n",
        "\n",
        "y_pred = load_and_predict_from_registry_auto(X_test_raw, stage=\"Production\")\n",
        "# - or, if you use aliases:\n",
        "# y_pred = load_and_predict_from_registry_auto(X_test_raw, alias=\"champion\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Evidently.ai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Preprocessing pipeline saved at: preprocess.pkl\n",
            "🚀 Running drift check: train_vs_val\n",
            "✅ Logged drift metrics for train_vs_val to MLflow.\n",
            "\n",
            "🚀 Running drift check: train_vs_test\n",
            "✅ Logged drift metrics for train_vs_test to MLflow.\n",
            "\n",
            "🚀 Running drift check: val_vs_test\n",
            "✅ Logged drift metrics for val_vs_test to MLflow.\n",
            "\n",
            "📌 Drift reports logged under run ID: 3cce5981ad6d435a995bf6f0d5a6b890\n",
            "🏃 View run at: http://127.0.0.1:5000/#/experiments/803647608902117050/runs/3cce5981ad6d435a995bf6f0d5a6b890\n",
            "🏃 View run drift_report_multi_split at: http://127.0.0.1:5000/#/experiments/803647608902117050/runs/3cce5981ad6d435a995bf6f0d5a6b890\n",
            "🧪 View experiment at: http://127.0.0.1:5000/#/experiments/803647608902117050\n"
          ]
        }
      ],
      "source": [
        "# ✅ STEP 1: Preprocess the full dataset using defined preprocessing pipeline\n",
        "preprocessor, numeric_features, categorical_features = build_preprocessing_pipeline(\n",
        "    X, ordinal_features, ordinal_mapping\n",
        ")\n",
        "processed = preprocessor.fit_transform(X)  # Fit + transform on full data\n",
        "\n",
        "# ✅ STEP 2: Extract column names from the preprocessor\n",
        "feature_names = preprocessor.get_feature_names_out()\n",
        "\n",
        "# ✅ STEP 3: Convert the processed NumPy array to DataFrame for downstream compatibility\n",
        "df_all = pd.DataFrame(processed, columns=feature_names)\n",
        "\n",
        "# ✅ STEP 4: Split the data into train/validation/test while maintaining label distribution (stratified)\n",
        "X_temp, X_test, y_temp, y_test = train_test_split(df_all, y, test_size=0.2, stratify=y, random_state=42)# train\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_temp, y_temp, test_size=0.25, stratify=y_temp, random_state=42)\n",
        "# Final: 60% train, 20% val, 20% test\n",
        "\n",
        "# ✅ STEP 5: Reindex splits to ensure column consistency (needed after preprocessing if sparse columns are dropped)\n",
        "def ensure_same_columns(df, reference_columns):\n",
        "    return df.reindex(columns=reference_columns, fill_value=0)  # fill missing columns with 0\n",
        "\n",
        "X_train = ensure_same_columns(X_train, feature_names)\n",
        "X_val = ensure_same_columns(X_val, feature_names)\n",
        "X_test = ensure_same_columns(X_test, feature_names)\n",
        "\n",
        "# ✅ STEP 6: Define the function to generate and log Evidently data drift reports\n",
        "def generate_and_log_drift_reports(X_train, X_val, X_test, output_dir, feature_names=None):\n",
        "    \"\"\"\n",
        "    Generates Evidently drift reports, saves HTMLs, and logs metrics to MLflow.\n",
        "\n",
        "    Args:\n",
        "        X_train, X_val, X_test (DataFrames): All splits to compare.\n",
        "        output_dir (str): Folder path to store drift report HTML files.\n",
        "        feature_names (list): Optional for reference.\n",
        "    \"\"\"\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "    # 📊 Define all pairs for comparison\n",
        "    comparisons = [\n",
        "        (\"train_vs_val\", X_train, X_val),\n",
        "        (\"train_vs_test\", X_train, X_test),\n",
        "        (\"val_vs_test\", X_val, X_test)\n",
        "    ]\n",
        "\n",
        "    # 🔗 Set up MLflow tracking and experiment\n",
        "    mlflow.set_tracking_uri(\"http://127.0.0.1:5000\")  # Local MLflow server\n",
        "    mlflow.set_experiment(\"Drift Monitoring\")        # Experiment name\n",
        "\n",
        "    # 🏃 Start MLflow run for drift logging\n",
        "    with mlflow.start_run(run_name=\"drift_report_multi_split\") as run:\n",
        "        for name, ref, curr in comparisons:\n",
        "            try:\n",
        "                print(f\"🚀 Running drift check: {name}\")\n",
        "                \n",
        "                # 📋 Create and run Evidently report\n",
        "                report = Report(metrics=[DataDriftPreset()])\n",
        "                report.run(reference_data=ref, current_data=curr)\n",
        "\n",
        "                # 💾 Save HTML report locally\n",
        "                html_path = os.path.join(output_dir, f'{name}.html')\n",
        "                report.save_html(html_path)\n",
        "\n",
        "                # 🧾 Log report as MLflow artifact\n",
        "                mlflow.log_artifact(html_path, artifact_path=\"evidently_html_reports\")\n",
        "\n",
        "                # 📈 Extract drift metrics from the report\n",
        "                drift_result = next(\n",
        "                    (m[\"result\"] for m in report.as_dict()[\"metrics\"]\n",
        "                     if m.get(\"metric\") == \"DataDriftTable\"),\n",
        "                    None\n",
        "                )\n",
        "\n",
        "                if drift_result:\n",
        "                    # ✅ Log drift ratio (how many columns are drifting)\n",
        "                    drift_ratio = drift_result[\"share_of_drifted_columns\"]\n",
        "                    mlflow.log_metric(f\"{name}_drift_ratio\", round(drift_ratio, 4))\n",
        "\n",
        "                    # ✅ Log drift score for each column\n",
        "                    for feature, vals in drift_result[\"drift_by_columns\"].items():\n",
        "                        score = vals.get(\"drift_score\")\n",
        "                        if score is not None:\n",
        "                            # Clean feature name for logging\n",
        "                            clean_name = re.sub(r'[^\\w\\d\\-./]', '', feature).replace(\" \", \"_\")\n",
        "                            mlflow.log_metric(f\"{name}_{clean_name}_drift_score\", round(score, 4))\n",
        "\n",
        "                print(f\"✅ Logged drift metrics for {name} to MLflow.\\n\")\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"❌ Drift report failed for {name}: {e}\")\n",
        "\n",
        "        # 🧭 Print final tracking info\n",
        "        print(f\"📌 Drift reports logged under run ID: {run.info.run_id}\")\n",
        "        print(f\"🏃 View run at: http://127.0.0.1:5000/#/experiments/{run.info.experiment_id}/runs/{run.info.run_id}\")\n",
        "\n",
        "# ✅ STEP 7: Call the drift logging function\n",
        "generate_and_log_drift_reports(\n",
        "    X_train,\n",
        "    X_val,\n",
        "    X_test,\n",
        "    output_dir=\"drift_reports\",\n",
        "    feature_names=feature_names\n",
        ")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "mypro",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
